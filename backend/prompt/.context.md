# Prompt 模块上下文信息

## 模块概述
Prompt模块是MetaPrompter项目的核心功能模块，负责管理提示词的创建、使用、优化和评估。

## 技术栈
- Django 5.2.6
- Django REST Framework
- LangChain
- OpenAI API

## 功能结构

### 数据模型
1. **Prompt**: 存储提示词的基本信息，包括名称、描述、内容等
2. **PromptHistory**: 记录用户对提示词的操作历史，支持create、update、use、optimize、generate、evaluate等操作类型
3. **PromptStatistics**: 存储提示词的统计信息，包括使用次数、评分、优化次数和生成次数等

### 目录结构
```
prompt/
├── __init__.py
├── admin.py
├── apps.py
├── migrations/
│   └── ...
├── models.py
├── serializers.py
├── urls.py
├── views.py
└── llm_utils/
    ├── __init__.py
    ├── config.py
    ├── template_manager.py
    └── service.py
```

### 核心功能
1. **提示词管理**：创建、更新、删除和查询提示词
2. **提示词使用**：记录提示词的使用情况
3. **提示词生成**：根据用户需求自动生成高质量提示词
4. **提示词优化**：使用LLM对现有提示词进行优化
5. **提示词评估**：评估提示词的质量并提供分析报告

## API 端点
- `/api/prompts/`: 提示词管理API
- `/api/prompts/<id>/use/`: 使用提示词
- `/api/prompts/generate/`: 生成新提示词
- `/api/prompts/<id>/optimize/`: 优化提示词
- `/api/prompts/<id>/evaluate/`: 评估提示词质量
- `/api/histories/`: 提示词历史记录API
- `/api/statistics/`: 提示词统计数据API
- `/api/public-prompts/`: 公共提示词列表API

## LLM 集成
Prompt模块通过`llm_utils`子目录集成了LLM功能：
- `config.py`: 配置LLM客户端和API密钥
- `template_manager.py`: 管理提示词模板
- `service.py`: 提供提示词生成、优化和评估等核心服务

## 最近更改
1. 添加了LLM相关目录结构和文件
2. 实现了提示词生成、优化和评估的核心服务
3. 集成LLM功能到现有API中
4. 更新了数据模型以支持新功能
5. 应用了数据库迁移